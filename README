# Multi-Core API Server with Queue Management

A **production-ready Express API server** that leverages Node.js clustering and Redis-based job queues to create a high-performance, scalable backend system. This application demonstrates enterprise-level architecture patterns including multi-core utilization, asynchronous job processing, and robust error handling with Dead Letter Queue (DLQ) implementation.

## ğŸš€ What This Application Is

This is a **comprehensive backend server template** that combines:

- **Multi-core Express API server** using Node.js clustering
- **Redis-based job queue system** with BullMQ for asynchronous task processing
- **Production-grade logging** with Winston and daily log rotation
- **Dead Letter Queue (DLQ)** for handling failed jobs
- **Docker containerization** for consistent deployment
- **Graceful shutdown handling** and automatic worker recovery

## ğŸ¯ What This Application Can Do

### Core Functionality

- **Handle HTTP requests** across multiple CPU cores simultaneously
- **Process background jobs** asynchronously using Redis queues
- **Automatically retry failed jobs** with exponential backoff
- **Capture permanently failed jobs** in a Dead Letter Queue for analysis
- **Provide real-time queue statistics** and monitoring endpoints
- **Log all operations** with structured, timestamped entries
- **Scale horizontally** by adding more worker processes

### API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Welcome message with worker process ID |
| GET | `/health` | Health check and server uptime |
| POST | `/jobs` | Add a new job to the processing queue |
| GET | `/queue/stats` | Get real-time queue statistics |

## ğŸ—ï¸ Architecture & How It Works

### Multi-Core Clustering

The application uses Node.js **cluster module** to:
- Fork one worker process per CPU core
- Distribute incoming HTTP requests across all workers
- Automatically restart crashed workers
- Maximize CPU utilization for better performance

### Queue System Architecture

```
HTTP Request â†’ Express API â†’ Add Job to Redis Queue â†’ BullMQ Worker â†’ Process Job
                                     â†“
                            Failed Job (after retries) â†’ Dead Letter Queue
```

### Key Components

**1. Master Process**
- Manages worker processes
- Handles worker lifecycle (spawn, monitor, restart)
- Distributes load across CPU cores

**2. Worker Processes**
- Handle HTTP requests independently
- Each runs its own Express server instance
- Share the same port through OS load balancing

**3. Queue System**
- **Redis**: Persistent job storage and queue management
- **BullMQ**: Advanced job queue with retry mechanisms
- **Job Processor**: Dedicated worker for background task execution

**4. Dead Letter Queue (DLQ)**
- Captures jobs that fail after all retry attempts
- Prevents infinite retry loops
- Allows manual inspection of problematic jobs

## ğŸ”§ Technologies Used & Their Roles

### Core Technologies

| Technology | Purpose | How It Works |
|------------|---------|--------------|
| **Node.js** | JavaScript runtime | Provides event-driven, non-blocking I/O for server-side execution |
| **Express** | Web framework | Handles HTTP routing, middleware, and request/response management |
| **cluster** | Multi-processing | Native Node.js module for spawning worker processes across CPU cores |
| **os** | System interface | Detects available CPU cores for optimal worker allocation |

### Queue & Storage

| Technology | Purpose | How It Works |
|------------|---------|--------------|
| **Redis** | In-memory data store | Stores job data, queue state, and provides pub/sub for real-time updates |
| **BullMQ** | Job queue library | Advanced queue management with retry logic, priorities, and failure handling |
| **ioredis** | Redis client | High-performance Redis client for Node.js with connection pooling |

### Production Features

| Technology | Purpose | How It Works |
|------------|---------|--------------|
| **Winston** | Logging library | Structured logging with multiple transports (file, console) and log rotation |
| **dotenv** | Configuration | Environment variable management for different deployment stages |
| **Docker** | Containerization | Consistent deployment across different environments |

## ğŸ“‹ Use Cases & Applications

### 1. **High-Traffic Web APIs**
- E-commerce platforms handling thousands of concurrent requests
- Social media APIs processing user interactions
- Real-time chat applications with message queuing

### 2. **Background Job Processing**
- **Email sending systems** with queue-based delivery
- **Image/video processing** pipelines
- **Data import/export** operations
- **Report generation** and file processing

### 3. **Microservices Architecture**
- Individual service in a distributed system
- Event-driven communication between services
- Asynchronous task delegation to other services

### 4. **Enterprise Applications**
- **Order processing systems** with workflow management
- **Notification services** with retry mechanisms
- **Data synchronization** between systems
- **Batch processing** of business operations

## ğŸ› ï¸ Project Structure

```
multi-core-api-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ index.js          # Environment configuration
â”‚   â”œâ”€â”€ logger/
â”‚   â”‚   â””â”€â”€ index.js          # Winston logging setup
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â”œâ”€â”€ index.js          # Queue management and DLQ
â”‚   â”‚   â””â”€â”€ worker.js         # Job processing worker
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ index.js          # Express routes and endpoints
â”‚   â”œâ”€â”€ app.js                # Express application setup
â”‚   â””â”€â”€ server.js             # Cluster master and worker logic
â”œâ”€â”€ logs/                     # Log files directory
â”œâ”€â”€ docker-compose.yml        # Multi-container orchestration
â”œâ”€â”€ Dockerfile               # Container build instructions
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ package.json             # Dependencies and scripts
â””â”€â”€ README.md               # This file
```

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ installed
- Docker and Docker Compose (optional)
- Redis server (local or cloud)

### Installation & Setup

1. **Clone and Install Dependencies**
```bash
git clone 
cd multi-core-api-server
npm install
```

2. **Configure Environment**
```bash
# Copy and edit environment variables
cp .env.example .env
```

3. **Start with Docker (Recommended)**
```bash
# Starts Redis, API server, and queue worker
docker-compose up -d
```

4. **Or Start Locally**
```bash
# Terminal 1: Start API server
npm start

# Terminal 2: Start queue worker
npm run worker
```

### Testing the Application

**Add a job to the queue:**
```bash
curl -X POST http://localhost:3000/jobs \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello from queue!", "shouldFail": false}'
```

**Check queue statistics:**
```bash
curl http://localhost:3000/queue/stats
```

**Health check:**
```bash
curl http://localhost:3000/health
```

## ğŸ” Key Features Explained

### 1. **Automatic Load Distribution**
When you make requests to the API, you'll notice different `workerPID` values in responses, showing that requests are being handled by different worker processes.

### 2. **Job Retry Mechanism**
Jobs automatically retry up to 3 times with exponential backoff (2s, 4s, 8s delays) before being moved to the Dead Letter Queue.

### 3. **Graceful Shutdown**
The application handles `SIGTERM` signals properly, allowing workers to finish current jobs before shutting down.

### 4. **Persistent Job Storage**
Jobs survive server restarts because they're stored in Redis with persistence enabled.

### 5. **Real-time Monitoring**
The `/queue/stats` endpoint provides live statistics about job processing, including counts of waiting, active, completed, and failed jobs.

## ğŸ“ Learning Opportunities

### Concepts to Deepen

**Advanced Node.js Patterns:**
- **Event-driven architecture** and how Node.js handles concurrency
- **Process communication** between master and workers
- **Memory management** in multi-process applications

**Queue System Mastery:**
- **Job prioritization** and scheduling strategies
- **Batch processing** and job chaining patterns
- **Queue monitoring** and performance optimization

**Production Deployment:**
- **Container orchestration** with Kubernetes
- **Load balancing** strategies for multi-instance deployments
- **Monitoring and alerting** for queue systems

**Redis Deep Dive:**
- **Redis data structures** and their use cases
- **Redis clustering** for high availability
- **Performance tuning** and memory optimization

## ğŸ”§ Customization & Extension

### Adding New Job Types
```javascript
// In src/queue/index.js
const emailQueue = new Queue('email-jobs', { connection: redisConfig });

// In src/queue/worker.js
const emailWorker = new Worker('email-jobs', async (job) => {
  // Email processing logic
});
```

### Adding Authentication
```javascript
// In src/app.js
const jwt = require('jsonwebtoken');

app.use('/jobs', (req, res, next) => {
  // JWT verification logic
});
```

### Database Integration
```javascript
// Add to dependencies
const mongoose = require('mongoose');
const { Pool } = require('pg');
```

## ğŸ“Š Performance Characteristics

- **Concurrent Request Handling:** Scales with CPU cores (8 cores = 8 concurrent request handlers)
- **Job Processing:** Configurable concurrency (default: 5 jobs simultaneously)
- **Memory Usage:** Efficient due to shared port and independent worker processes
- **Fault Tolerance:** Automatic worker restart and job retry mechanisms

## ğŸ¯ Production Readiness

This application includes essential production features:

- âœ… **Multi-core utilization** for maximum performance
- âœ… **Structured logging** with log rotation
- âœ… **Error handling** and recovery mechanisms
- âœ… **Health checks** for monitoring
- âœ… **Graceful shutdown** handling
- âœ… **Environment-based configuration**
- âœ… **Containerization** for consistent deployment
- âœ… **Job persistence** and retry logic

## ğŸ“ License

MIT License - feel free to use this as a foundation for your own projects.

**This application demonstrates enterprise-level backend engineering practices and serves as a robust foundation for building scalable, production-ready APIs with asynchronous job processing capabilities.**
